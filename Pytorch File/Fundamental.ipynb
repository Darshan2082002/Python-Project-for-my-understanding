{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d607753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "print(torch . __version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb88027a",
   "metadata": {},
   "source": [
    "Creating Tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "608763c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar\n",
    "scalar=torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2383cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scalar Dimensional \n",
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05117b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #Tensor back as Int type\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8489b0b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vector \n",
    "vector=torch.tensor([7,1])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af18d5f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vector Ndim\n",
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f8825af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fece17d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7, 8],\n",
       "        [8, 7]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#matrix \n",
    "MARTIX=torch.tensor([[7,8],[8,7]])\n",
    "MARTIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e61ec6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MARTIX.ndim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fbafe7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 8])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MARTIX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26e03815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 7])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MARTIX[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a338e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MARTIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acd8ad8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [1, 4, 5],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor\n",
    "TENSOR=torch.tensor([[[1,2,3],\n",
    "                     [1,4,5],\n",
    "                     [7,8,9]]])\n",
    "TENSOR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec5b8f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28544f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebb3861a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [1, 4, 5],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d13df15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad5434c",
   "metadata": {},
   "source": [
    "## Random Tensors\n",
    "Why random Tensors?\n",
    " \n",
    "Random Tensors are important because the way many neural networks learn is that they start with tensors full of random numbers and tehn adjust those reandom numbers to better represent the data.represent \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f822c1fe",
   "metadata": {},
   "source": [
    "Start twith random numbers -> look at data-> update random numbers-> look at data -> update the random numbers \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e806a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4295, 0.3955, 0.8417, 0.6901, 0.8534, 0.7016, 0.0419, 0.1411, 0.2214,\n",
       "         0.5225],\n",
       "        [0.5159, 0.2035, 0.0462, 0.0657, 0.4551, 0.3032, 0.4839, 0.5603, 0.5398,\n",
       "         0.4902],\n",
       "        [0.5415, 0.9954, 0.0157, 0.7955, 0.3218, 0.4446, 0.5303, 0.3888, 0.3865,\n",
       "         0.8849],\n",
       "        [0.8166, 0.3571, 0.4345, 0.8023, 0.3233, 0.4945, 0.3757, 0.6683, 0.0719,\n",
       "         0.6234],\n",
       "        [0.9023, 0.7089, 0.2497, 0.5586, 0.5528, 0.3316, 0.9647, 0.7137, 0.0218,\n",
       "         0.5985],\n",
       "        [0.7529, 0.0590, 0.7849, 0.0946, 0.9900, 0.2059, 0.2348, 0.0282, 0.0465,\n",
       "         0.4920],\n",
       "        [0.1738, 0.9256, 0.9207, 0.2657, 0.1165, 0.5245, 0.1149, 0.1231, 0.3308,\n",
       "         0.6119],\n",
       "        [0.2188, 0.3238, 0.3021, 0.3190, 0.5845, 0.4268, 0.1617, 0.4554, 0.2728,\n",
       "         0.3099],\n",
       "        [0.4213, 0.0061, 0.1924, 0.5047, 0.1626, 0.9737, 0.7377, 0.0166, 0.7282,\n",
       "         0.6998],\n",
       "        [0.7048, 0.2753, 0.5591, 0.5686, 0.2441, 0.9261, 0.5322, 0.6051, 0.7402,\n",
       "         0.2698]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a random tensors of size or shape(3,4)\n",
    "random=torch.rand(3,4)\n",
    "random \n",
    "random1=torch.rand(10,10)\n",
    "random1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c105ca73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfe36dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, torch.Size([224, 224, 3]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a random tensor with similar shape to an image tensor \n",
    "rando_image_size_tensor=torch.rand(size=(224,224,3))# height,width, Colour Channel  \n",
    "rando_image_size_tensor.ndim, rando_image_size_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f676af2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7387, 0.9462, 0.8361,  ..., 0.9972, 0.1439, 0.8872],\n",
       "        [0.9272, 0.7877, 0.9994,  ..., 0.8084, 0.4627, 0.5887],\n",
       "        [0.4361, 0.8315, 0.4309,  ..., 0.4455, 0.4713, 0.3413],\n",
       "        ...,\n",
       "        [0.4645, 0.4761, 0.0287,  ..., 0.1505, 0.7446, 0.6921],\n",
       "        [0.1706, 0.1748, 0.1119,  ..., 0.4177, 0.6740, 0.2794],\n",
       "        [0.7453, 0.2909, 0.2062,  ..., 0.3796, 0.6346, 0.3131]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Random=torch.rand(224,224)\n",
    "Random \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e2ad790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Random.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2abe9683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([224, 224])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Random.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1b9d52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8020, 0.3138, 0.0732,  ..., 0.3577, 0.4946, 0.4311],\n",
       "         [0.6474, 0.3109, 0.4277,  ..., 0.1454, 0.3145, 0.1107],\n",
       "         [0.5804, 0.2744, 0.1649,  ..., 0.9087, 0.4074, 0.7517],\n",
       "         ...,\n",
       "         [0.4844, 0.8046, 0.1937,  ..., 0.6182, 0.7950, 0.9191],\n",
       "         [0.3934, 0.9519, 0.5564,  ..., 0.3841, 0.0274, 0.4634],\n",
       "         [0.1027, 0.0582, 0.6274,  ..., 0.2498, 0.8767, 0.8003]],\n",
       "\n",
       "        [[0.4326, 0.1036, 0.1396,  ..., 0.3924, 0.9374, 0.3755],\n",
       "         [0.5790, 0.1065, 0.8839,  ..., 0.2659, 0.5831, 0.8692],\n",
       "         [0.1540, 0.7514, 0.6502,  ..., 0.4867, 0.4019, 0.3001],\n",
       "         ...,\n",
       "         [0.8701, 0.1553, 0.1716,  ..., 0.9804, 0.3360, 0.4295],\n",
       "         [0.6908, 0.0511, 0.9950,  ..., 0.1323, 0.8585, 0.3348],\n",
       "         [0.3030, 0.5132, 0.0315,  ..., 0.8161, 0.7324, 0.7696]],\n",
       "\n",
       "        [[0.2398, 0.4591, 0.1717,  ..., 0.2355, 0.8271, 0.6659],\n",
       "         [0.0461, 0.0419, 0.3181,  ..., 0.2752, 0.1171, 0.5000],\n",
       "         [0.9565, 0.6764, 0.3951,  ..., 0.7988, 0.8565, 0.5639],\n",
       "         ...,\n",
       "         [0.9932, 0.7335, 0.2788,  ..., 0.0752, 0.0727, 0.7460],\n",
       "         [0.0434, 0.6242, 0.3349,  ..., 0.6868, 0.3968, 0.0992],\n",
       "         [0.9886, 0.8614, 0.0807,  ..., 0.7405, 0.3318, 0.2823]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " torch.rand((3,224,244))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80a0aa55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "### Zero and Ones\n",
    "Zero =torch.zeros(3,4)\n",
    "print(Zero)\n",
    "# 0 multipled with any tensor is becomes zeros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bdf033f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a tensors of all ones\n",
    "ones=torch.ones(3,4)\n",
    "# it convert all the number into ones\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37527640",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating a range of tensors and tensors-like \n",
    "#use torch.range()\n",
    "# range as been replaced by arange \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59fd9bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20c75ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "one=torch.arange(start=0,end=10000,step=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a9de7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating tensors like \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "494aebfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros_like(one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9430b162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tensor  data type \n",
    "float_32_tensor= torch.tensor ([3.0,6.0,9.0],\n",
    "                               dtype=None,\n",
    "                               device=None,# what device is you tensor on \n",
    "                               requires_grad=False) # whether or  not to track Gradients\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ceb343f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note tensor data type is one of the 3 big errors you will run into PYtorch \n",
    "## Tensor not right datatype\n",
    "## Tensor  not right shape\n",
    "## Tensor  not on the right device \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "17161063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting float 32 into float 16\n",
    "floar_16_tensor= float_32_tensor.type(torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "616e1021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "floar_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c60b281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor*floar_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2b395a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 8], dtype=torch.int32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# interger \n",
    "int_32=torch.tensor([3,6,8],dtype=torch.int32)\n",
    "int_32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5b5a6d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 72.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32*float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a0839126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 8])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_64=torch.tensor([3,6,8],dtype=torch.int64)\n",
    "int_64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f6955e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 72.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_64* float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "810e6c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 8])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_long=torch.tensor([3,6,8],dtype=torch.long)\n",
    "int_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "46307cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 72.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor*int_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1e7515c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Getting information from tensor \n",
    "### Tensor not right datatype -> to do get datatype from a tensor can use tensor.dtype\n",
    "### Tensor not right shape -> to get shape from a tensor  can use tensor.shape\n",
    "### Tensor not on the right device-> to get device from a tensor, can use tensor. device \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e1301c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9998, 0.7478, 0.2135, 0.9024],\n",
       "        [0.1090, 0.3198, 0.3518, 0.6768],\n",
       "        [0.1513, 0.0330, 0.0615, 0.2831]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor =torch.rand(3,4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2ac9f304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9998, 0.7478, 0.2135, 0.9024],\n",
      "        [0.1090, 0.3198, 0.3518, 0.6768],\n",
      "        [0.1513, 0.0330, 0.0615, 0.2831]])\n",
      "Datatype of tensor:torch.float32\n",
      "shape of tensor:torch.Size([3, 4])\n",
      "Devic of tensor:cpu\n"
     ]
    }
   ],
   "source": [
    "print(some_tensor)\n",
    "print(f\"Datatype of tensor:{some_tensor.dtype}\")\n",
    "print(f\"shape of tensor:{some_tensor.shape}\")\n",
    "print(f\"Devic of tensor:{some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0c83aade",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Manipulating Tensor \n",
    "\n",
    "# Tensor operation Include\n",
    "# ADD\n",
    "# sub\n",
    "# Multiplicatio\n",
    "# Division\n",
    "# Matrix Multiplication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a6fafe55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([101, 102, 103])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### create a tensor \n",
    "tensor =torch.tensor([1,2,3])\n",
    "tensor + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f3bfba13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8c369382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "35212190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 9])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor * tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "96a0be45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor/tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "649894bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try out pytroch in-built function \n",
    "torch.mul(tensor,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8c9baea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(tensor,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "12dc8515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.div(tensor,tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aa27948c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sub(tensor,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0014ae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Matrix multiplication \n",
    "## Two main ways of performing multiplication in neural and DL\n",
    "## 1. Element wise Multiplication\n",
    "## 2. Matrix Multiplication (dot Product) . _>\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f55fc2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals:tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "## 1. Element wise Multiplication\n",
    "print(tensor,\"*\",tensor)\n",
    "print(f\"Equals:{tensor*tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fd9ce7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 566 Î¼s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor,tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "17f9935e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  One of the most commen error  in dl is shape error \n",
    "## There are two main rule that performing matrix multiplication needs to satisfy\n",
    "## @ stand for multiplication \n",
    "## The inner dimension must match\n",
    "#(3,2)@ (3,2) Will not work\n",
    "#(3,2)@ (2,3) will work \n",
    "\n",
    "# The Resulting matrix has the shape of the \"outer Dimensions\"\n",
    "# One of the most common error in deep learning \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e12e6d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darsh\\AppData\\Local\\Temp\\ipykernel_3924\\1402565077.py:3: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:4419.)\n",
      "  tensor.T # Stand for Transpose\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To fix the shape using Transpose\n",
    "\n",
    "tensor.T # Stand for Transpose \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eabcee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the min max mean and sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4fe7372d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a tensor \n",
    "z= torch.arange(0,100,10)\n",
    "z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b74f82ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d145bd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(90)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fb316129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(45.)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(z.type(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "497da186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(450)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch shape and dtype can be stored \n",
    "torch.sum(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4eeefcd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the position of min  and max\n",
    "z.argmin() # -> return min val back from the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2786c991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the position  in tensor that has the maximum value with argmax()\n",
    "z.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8d55e070",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reshpaing Stacking  and Squeezing \n",
    "\n",
    "# * Reshaping reshapes an input tensor to a defined shape\n",
    "# View - return of an input  tensor of certainn shape but keep the same memory as orginial tensor \n",
    "# stack ->  Combine multiple tensors on top of each other(vstack) or side by side(hstack)\n",
    "# Squeeze- remove all '1'  dimension  from a tensor \n",
    "# * Unsequee add a '1' dimension to a target tensor \n",
    "## Permute Return a view of the input with dimension permuted \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "14c230ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a tensor \n",
    "import torch\n",
    "z=torch.arange(1.,10.)\n",
    "z,z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7b162a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.],\n",
       "         [2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [7.],\n",
       "         [8.],\n",
       "         [9.]]),\n",
       " torch.Size([9, 1]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_reshape=z.reshape(9,1)\n",
    "z_reshape,z_reshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e546d5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change the view \n",
    "x=z.view(1,9)\n",
    "x,x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ba52542e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changinf z change z (because a view of  a tensor share the same memory as the original )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "da8742a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [2., 2., 2., 2.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [4., 4., 4., 4.],\n",
       "        [5., 5., 5., 5.],\n",
       "        [6., 6., 6., 6.],\n",
       "        [7., 7., 7., 7.],\n",
       "        [8., 8., 8., 8.],\n",
       "        [9., 9., 9., 9.]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stack tensor on top of each other \n",
    "x_stacked=torch.stack([z,z,z,z],dim=1)\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f13a6ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 1])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch .squeeze-> from all the singel dimension \n",
    "z_reshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c541e745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_reshape.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "640c35a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_reshape.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "eddc26a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.],\n",
       "         [2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [7.],\n",
       "         [8.],\n",
       "         [9.]]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_reshape.unsqueeze(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0fc6db48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 3])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch permute \n",
    "s=torch.rand(2,3,4)\n",
    "s_permut=s.permute(2,0,1) # shif the axis 0->1 1->2 2->0\n",
    "s_permut.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1c012919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting  data (Indexing)\n",
    "\n",
    "\n",
    "#Indexing with Pytorch is similar to indexing with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "63b583fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "z=torch.arange(1,10).reshape(1,3,3)\n",
    "z, z.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4c79d88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's index  on our new tensor \n",
    "z[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f2ea28b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's Index on the middle bracket (dim=1)\n",
    "z[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ff120a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's Index on the most inner bracket (last Dimesnsion )\n",
    "z[0][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "de936d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[0][2][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7962ee99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can also use \":\" to select \"all\" of a target dimension \n",
    "x[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3029db6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 8]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of 0th and qst dimension but only index 1 of 2nd dimension \n",
    "z[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0394a2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of the 0 dimension but only the 1 index value of 1st and 2nd dimension \n",
    "z[:,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2171918c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Index 0 of 0th and 1s dimension and all values of 2nd dimension \n",
    "z[0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f268fd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9)\n",
      "tensor([[3, 6, 9]])\n"
     ]
    }
   ],
   "source": [
    "#Index on z to return 9\n",
    "print(z[0,2,2])\n",
    "#index on  z to return 3,6,9\n",
    "print(z[:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2858c6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy and Pytorch tensors\n",
    "# Numpy is a popular scientific python numerical computing\n",
    "# and because of this, pytorch has functionality to interact with it\n",
    "# data in Numpy  want in pytorch tensor 'torch.from_numpy(ndarray) '\n",
    "# Pytoech tensor-> Numpy-> torch.tensor.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71535dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6 7]\n",
      "(7,)\n",
      "7\n",
      "tensor \n",
      "Tensor size:<built-in method size of Tensor object at 0x000001E3E4955540>\n",
      "Tensor shape:torch.Size([7])\n",
      "Tensor torch.float32\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import numpy as np \n",
    "array=np.arange(1,8)\n",
    "print(array)\n",
    "print(array.shape)\n",
    "print(array.size)\n",
    "tensor=torch.from_numpy(array).type(torch.float32)# waring: when converting from numpy -> pytorch  pytorch reflect numpy default  one \n",
    "\n",
    "print('tensor ')\n",
    "print(f\"Tensor size:{tensor.size}\")\n",
    "print(f\"Tensor shape:{tensor.shape}\")\n",
    "print(f\"Tensor {tensor.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c437b37d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
